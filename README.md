# ğŸš€ Real-Time Loan Default Risk Analytics  
**Databricks | PySpark | Delta Lake | SQL | Power BI**

---

## ğŸ“Œ Project Overview

This project implements an end-to-end **data engineering and analytics pipeline** to analyze loan repayment behavior and identify **default-prone customers**, **high-risk loans**, and **branch-wise performance**.  

The system processes batch loan data using **Databricks & PySpark**, stores curated data in **Delta Lake**, applies **machine learning for default prediction**, and visualizes insights using **Power BI dashboards**.

---

## ğŸ¯ Business Problem

Banks face significant losses due to:
- Loan defaults  
- Poor credit risk monitoring  
- Delayed identification of high-risk customers  

ğŸ‘‰ This solution enables **early risk detection** through analytics and ML-driven insights.

---

## ğŸ—ï¸ Architecture (Medallion Pattern)

Raw CSV Files
â†“
ğŸ¥‰ Bronze Layer (Raw Ingestion)
â†“
ğŸ¥ˆ Silver Layer (Cleaned & Validated)
â†“
ğŸ¥‡ Gold Layer (Business Metrics & ML)
â†“
ğŸ“Š Power BI Dashboards


---

## ğŸ› ï¸ Tech Stack

### Data Engineering
- Databricks
- Apache Spark (PySpark)
- Spark SQL
- Delta Lake

### Machine Learning
- Spark MLlib
- Logistic Regression

### Visualization
- Power BI (DirectQuery via Databricks SQL)

---

## ğŸ“‚ Dataset Description

| Dataset | Description |
|------|------------|
| `credit_risk_applicants.csv` | Loan applicant & customer profile data |
| `credit_risk_previous_loans.csv` | Historical loan & repayment behavior |
| Metadata file | Column definitions (documentation only) |

---

## ğŸ”„ Data Engineering Workflow

### 1ï¸âƒ£ Bronze Layer â€“ Ingestion
- Load raw CSV files from DBFS
- Store data as Delta tables
- Add batch date for tracking

### 2ï¸âƒ£ Silver Layer â€“ Cleaning & Validation
- Handle missing values
- Remove duplicate records
- Fix invalid loan statuses
- Add EMI overdue logic

### 3ï¸âƒ£ Gold Layer â€“ Analytics
- Customer risk profiling
- Branch-wise default analysis
- Loan aging buckets
- EMI overdue metrics

### 4ï¸âƒ£ Machine Learning
- Feature engineering
- Logistic Regression model
- Default probability prediction
- Risk categorization

---

## ğŸ“Š Power BI Dashboards

### ğŸ“Š Dashboard 1: ML Risk Overview
- Total customers
- High-risk customers
- Branch vs default probability
- Customer risk table

### ğŸ“Š Dashboard 2: EMI Risk
- Total EMI overdue amount
- Overdue trend by batch date
- Overdue vs non-overdue distribution

### ğŸ“Š Dashboard 3: Model Performance
- Actual vs predicted defaults
- Average default probability
- Risk category distribution

---

## ğŸ“ Repository Structure

Real-Time-Loan-Default-Risk-Analytics/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_Bronze_Ingestion.py
â”‚ â”œâ”€â”€ 02_Silver_Cleaning.py
â”‚ â”œâ”€â”€ 03_Gold_Analytics.py
â”‚ â””â”€â”€ 04_ML_Default_Prediction.py
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ powerbi_queries.sql
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ PowerBI_Connection_Guide.md
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

## ğŸ”— Power BI Connection

- **Connector**: Azure Databricks  
- **Mode**: DirectQuery  
- **Source**: Gold Delta tables via Databricks SQL Warehouse  

---

## ğŸ“ˆ Key Outcomes

- Identified high-risk customers before default
- Enabled branch-wise performance tracking
- Automated loan risk analytics pipeline
- ML-driven default prediction
- Real-time dashboards for decision-makers

---

## ğŸ¤ Interview Summary

> *â€œThis project demonstrates a production-style data engineering pipeline using Databricks and PySpark to analyze loan default risk. It integrates Delta Lake for reliability, Spark ML for prediction, and Power BI for real-time business insights.â€*

---

## ğŸ“Œ Notes

- Large datasets are intentionally excluded from GitHub  
- Data resides in Databricks DBFS  
- GitHub contains only **code, SQL, and documentation**

---

## ğŸ§‘â€ğŸ’» Author
**Vishwatej Shivaji Shinde**  
_Data Engineering | Analytics | Banking Domain_
